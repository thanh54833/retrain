# H∆∞·ªõng D·∫´n Ch·ªçn Ph∆∞∆°ng Ph√°p PEFT Cho Dataset Rephrase

## T·ªïng Quan

T√†i li·ªáu n√†y ph√¢n t√≠ch dataset Rephrase v√† ƒë·ªÅ xu·∫•t ph∆∞∆°ng ph√°p PEFT t·ªëi ∆∞u nh·∫•t d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm c·ª• th·ªÉ c·ªßa dataset n√†y.

## Ph√¢n T√≠ch Dataset

### ƒê·∫∑c ƒêi·ªÉm Ch√≠nh

| ƒê·∫∑c ƒêi·ªÉm | Gi√° Tr·ªã | √ù Nghƒ©a |
|----------|---------|---------|
| **S·ªë l∆∞·ª£ng samples** | 1,000 | Dataset nh·ªè, c·∫ßn √≠t tham s·ªë ƒë·ªÉ tr√°nh overfitting |
| **Task type** | Text-to-JSON Generation | C·∫ßn model generation t·ªët, output structured |
| **Language** | Ti·∫øng Vi·ªát | C·∫ßn model h·ªó tr·ª£ ti·∫øng Vi·ªát |
| **Input length** | Avg 15.72 chars (1-74) | Input ng·∫Øn, ƒë∆°n gi·∫£n |
| **Output length** | Avg 25-120 chars | Output d√†i h∆°n, ph·ª©c t·∫°p (JSON) |
| **Class imbalance** | 96.1% in-scope, 3.9% out-of-scope | M·∫•t c√¢n b·∫±ng, c·∫ßn x·ª≠ l√Ω c·∫©n th·∫≠n |
| **Output format** | Structured JSON | C·∫ßn valid JSON, ch√≠nh x√°c cao |

### Y√™u C·∫ßu C·ª• Th·ªÉ

1. **Text Generation**: Model c·∫ßn generate text (JSON output)
2. **Structured Output**: Output ph·∫£i l√† valid JSON v·ªõi 5 tr∆∞·ªùng
3. **Vietnamese Language**: Model ph·∫£i hi·ªÉu v√† t·∫°o text ti·∫øng Vi·ªát
4. **Small Dataset**: 1K samples ‚Üí C·∫ßn √≠t tham s·ªë ƒë·ªÉ tr√°nh overfitting
5. **Precision**: C·∫ßn ƒë·ªô ch√≠nh x√°c cao cho JSON format

## ƒê√°nh Gi√° C√°c Ph∆∞∆°ng Ph√°p PEFT

### 1. Prompt Tuning

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.001% (√≠t nh·∫•t)
- T·ªëc ƒë·ªô: Ch·∫≠m (c·∫ßn nhi·ªÅu epochs)
- ƒê·ªô ph·ª©c t·∫°p: Th·∫•p

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - √çt tham s·ªë nh·∫•t, ph√π h·ª£p dataset nh·ªè
  - √çt nguy c∆° overfitting
  - ƒê∆°n gi·∫£n, d·ªÖ tri·ªÉn khai
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Ch·∫≠m (c·∫ßn 20-50 epochs)
  - C√≥ th·ªÉ kh√¥ng ƒë·ªß m·∫°nh cho structured JSON output ph·ª©c t·∫°p
  - Learning rate cao, c√≥ th·ªÉ kh√¥ng ·ªïn ƒë·ªãnh

**ƒê√°nh gi√°**: ‚ö†Ô∏è **C√≥ th·ªÉ th·ª≠ nh∆∞ng kh√¥ng t·ªëi ∆∞u**

### 2. P-tuning

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.05%
- T·ªëc ƒë·ªô: Ch·∫≠m (c·∫ßn nhi·ªÅu epochs)
- ƒê·ªô ph·ª©c t·∫°p: Trung b√¨nh

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - √çt tham s·ªë, ph√π h·ª£p dataset nh·ªè
  - Linh ho·∫°t trong vi·ªác ƒë·∫∑t prompt
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Ch·∫≠m (c·∫ßn nhi·ªÅu epochs)
  - C√≥ th·ªÉ kh√¥ng ƒë·ªß m·∫°nh cho JSON generation
  - Ph·ª©c t·∫°p h∆°n Prompt Tuning

**ƒê√°nh gi√°**: ‚ö†Ô∏è **Kh√¥ng khuy·∫øn ngh·ªã**

### 3. Prefix Tuning

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.18%
- T·ªëc ƒë·ªô: Ch·∫≠m (c·∫ßn nhi·ªÅu epochs)
- ƒê·ªô ph·ª©c t·∫°p: Cao

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - Hi·ªáu su·∫•t cao
  - T·ªët cho c√°c t√°c v·ª• ph·ª©c t·∫°p
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Nhi·ªÅu tham s·ªë h∆°n (0.18% c√≥ th·ªÉ qu√° nhi·ªÅu cho 1K samples)
  - Nguy c∆° overfitting cao v·ªõi dataset nh·ªè
  - Ch·∫≠m, c·∫ßn nhi·ªÅu epochs

**ƒê√°nh gi√°**: ‚ùå **Kh√¥ng ph√π h·ª£p** (qu√° nhi·ªÅu tham s·ªë cho dataset nh·ªè)

### 4. LoRA

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.13-0.77% (t√πy rank)
- T·ªëc ƒë·ªô: Nhanh
- ƒê·ªô ph·ª©c t·∫°p: Th·∫•p

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - Nhanh, h·ªôi t·ª• nhanh (5-10 epochs)
  - C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh rank (r=8-16 cho dataset nh·ªè)
  - ·ªîn ƒë·ªãnh, ƒë∆∞·ª£c h·ªó tr·ª£ r·ªông r√£i
  - T·ªët cho text generation
  - C√≥ th·ªÉ ki·ªÉm so√°t s·ªë tham s·ªë qua rank
- ‚ö†Ô∏è **L∆∞u √Ω**: 
  - C·∫ßn ch·ªçn rank ph√π h·ª£p (r=8-16 cho dataset nh·ªè)
  - C√≥ th·ªÉ c·∫ßn th·ª≠ nghi·ªám v·ªõi c√°c rank kh√°c nhau

**ƒê√°nh gi√°**: ‚úÖ **Ph√π h·ª£p nh·∫•t** - L·ª±a ch·ªçn t·ªëi ∆∞u

### 5. LoHa

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~1.44%
- T·ªëc ƒë·ªô: Nhanh
- ƒê·ªô ph·ª©c t·∫°p: Trung b√¨nh

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - Rank hi·ªáu qu·∫£ cao h∆°n (r¬≤)
  - Nhanh
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Nhi·ªÅu tham s·ªë h∆°n (1.44% c√≥ th·ªÉ qu√° nhi·ªÅu cho 1K samples)
  - Nguy c∆° overfitting cao
  - Ph·ª©c t·∫°p h∆°n LoRA

**ƒê√°nh gi√°**: ‚ùå **Kh√¥ng ph√π h·ª£p** (qu√° nhi·ªÅu tham s·ªë)

### 6. LoKr

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.13%
- T·ªëc ƒë·ªô: Nhanh
- ƒê·ªô ph·ª©c t·∫°p: Trung b√¨nh

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - √çt tham s·ªë (t∆∞∆°ng t·ª± LoRA r=8)
  - Nhanh
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Ph·ª©c t·∫°p h∆°n LoRA
  - √çt t√†i li·ªáu v√† v√≠ d·ª• h∆°n
  - Kh√¥ng c√≥ l·ª£i th·∫ø r√µ r√†ng so v·ªõi LoRA

**ƒê√°nh gi√°**: ‚ö†Ô∏è **C√≥ th·ªÉ th·ª≠ nh∆∞ng LoRA t·ªët h∆°n**

### 7. AdaLoRA

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.59%
- T·ªëc ƒë·ªô: Nhanh
- ƒê·ªô ph·ª©c t·∫°p: Cao

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - Ph√¢n b·ªï tham s·ªë th√¥ng minh
  - Hi·ªáu su·∫•t cao
- ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**: 
  - Nhi·ªÅu tham s·ªë h∆°n (0.59% c√≥ th·ªÉ qu√° nhi·ªÅu cho 1K samples)
  - Ph·ª©c t·∫°p, c·∫ßn custom training loop
  - Nguy c∆° overfitting v·ªõi dataset nh·ªè

**ƒê√°nh gi√°**: ‚ùå **Kh√¥ng ph√π h·ª£p** (qu√° nhi·ªÅu tham s·ªë v√† ph·ª©c t·∫°p)

### 8. IA3

**ƒê·∫∑c ƒëi·ªÉm**:
- Tham s·ªë trainable: ~0.02%
- T·ªëc ƒë·ªô: R·∫•t nhanh
- ƒê·ªô ph·ª©c t·∫°p: Th·∫•p

**Ph√π h·ª£p v·ªõi dataset n√†y?**
- ‚úÖ **∆Øu ƒëi·ªÉm**: 
  - R·∫•t √≠t tham s·ªë (~0.02%), ph√π h·ª£p dataset nh·ªè
  - R·∫•t nhanh, h·ªôi t·ª• nhanh
  - √çt nguy c∆° overfitting
- ‚ö†Ô∏è **L∆∞u √Ω**: 
  - T·ªët nh·∫•t cho Seq2Seq models
  - C√≥ th·ªÉ kh√¥ng ƒë·ªß m·∫°nh cho structured JSON output ph·ª©c t·∫°p
  - √çt t√†i li·ªáu h∆°n LoRA

**ƒê√°nh gi√°**: ‚úÖ **Ph√π h·ª£p** - L·ª±a ch·ªçn thay th·∫ø t·ªët n·∫øu d√πng Seq2Seq model

## So S√°nh Tr·ª±c Ti·∫øp

| Ph∆∞∆°ng Ph√°p | Tham S·ªë | T·ªëc ƒê·ªô | Ph√π H·ª£p Dataset Nh·ªè | Ph√π H·ª£p JSON Gen | ƒê√°nh Gi√° |
|-------------|---------|--------|---------------------|------------------|----------|
| **Prompt Tuning** | ~0.001% | Ch·∫≠m | ‚úÖ R·∫•t t·ªët | ‚ö†Ô∏è C√≥ th·ªÉ | ‚ö†Ô∏è C√≥ th·ªÉ th·ª≠ |
| **P-tuning** | ~0.05% | Ch·∫≠m | ‚úÖ T·ªët | ‚ö†Ô∏è C√≥ th·ªÉ | ‚ùå Kh√¥ng khuy·∫øn ngh·ªã |
| **Prefix Tuning** | ~0.18% | Ch·∫≠m | ‚ùå Qu√° nhi·ªÅu | ‚úÖ T·ªët | ‚ùå Kh√¥ng ph√π h·ª£p |
| **LoRA (r=8)** | ~0.13% | Nhanh | ‚úÖ R·∫•t t·ªët | ‚úÖ T·ªët | ‚úÖ **T·ªëi ∆∞u** |
| **LoRA (r=16)** | ~0.26% | Nhanh | ‚úÖ T·ªët | ‚úÖ R·∫•t t·ªët | ‚úÖ **T·ªëi ∆∞u** |
| **LoHa** | ~1.44% | Nhanh | ‚ùå Qu√° nhi·ªÅu | ‚úÖ T·ªët | ‚ùå Kh√¥ng ph√π h·ª£p |
| **LoKr** | ~0.13% | Nhanh | ‚úÖ T·ªët | ‚úÖ T·ªët | ‚ö†Ô∏è C√≥ th·ªÉ th·ª≠ |
| **AdaLoRA** | ~0.59% | Nhanh | ‚ùå Qu√° nhi·ªÅu | ‚úÖ T·ªët | ‚ùå Kh√¥ng ph√π h·ª£p |
| **IA3** | ~0.02% | R·∫•t nhanh | ‚úÖ R·∫•t t·ªët | ‚ö†Ô∏è C√≥ th·ªÉ | ‚úÖ Thay th·∫ø t·ªët |

## ƒê·ªÅ Xu·∫•t Gi·∫£i Ph√°p

### Gi·∫£i Ph√°p T·ªëi ∆Øu: LoRA v·ªõi r=8 ho·∫∑c r=16

**L√Ω do ch·ªçn LoRA**:

1. **Ph√π h·ª£p dataset nh·ªè**:
   - V·ªõi r=8: ~0.13% tham s·ªë (ph√π h·ª£p 1K samples)
   - V·ªõi r=16: ~0.26% tham s·ªë (v·∫´n an to√†n cho 1K samples)
   - C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh rank d·ªÖ d√†ng

2. **Nhanh v√† hi·ªáu qu·∫£**:
   - H·ªôi t·ª• nhanh (5-10 epochs)
   - Kh√¥ng c·∫ßn nhi·ªÅu epochs nh∆∞ prompt-based methods
   - Ti·∫øt ki·ªám th·ªùi gian v√† t√†i nguy√™n

3. **T·ªët cho text generation**:
   - LoRA ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët cho generation tasks
   - C√≥ th·ªÉ handle structured output (JSON)
   - ƒê∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i cho c√°c t√°c v·ª• t∆∞∆°ng t·ª±

4. **·ªîn ƒë·ªãnh v√† ƒë∆∞·ª£c h·ªó tr·ª£**:
   - Nhi·ªÅu t√†i li·ªáu v√† v√≠ d·ª•
   - C·ªông ƒë·ªìng h·ªó tr·ª£ t·ªët
   - D·ªÖ debug v√† troubleshoot

5. **Linh ho·∫°t**:
   - C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh rank d·ª±a tr√™n k·∫øt qu·∫£
   - C√≥ th·ªÉ th·ª≠ nghi·ªám v·ªõi c√°c target_modules kh√°c nhau
   - D·ªÖ d√†ng fine-tune hyperparameters

### C·∫•u H√¨nh ƒê·ªÅ Xu·∫•t

#### Option 1: LoRA Conservative (r=8) - Khuy·∫øn ngh·ªã b·∫Øt ƒë·∫ßu

```python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=8,                          # Rank th·∫•p cho dataset nh·ªè
    lora_alpha=16,               # 2 * r
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # Attention layers
    lora_dropout=0.1,            # Dropout ƒë·ªÉ tr√°nh overfitting
    bias="none",                  # Kh√¥ng train bias
    task_type="CAUSAL_LM" ho·∫∑c "SEQ_2_SEQ_LM"  # T√πy model base
)
```

**Khi n√†o d√πng**:
- B·∫Øt ƒë·∫ßu th·ª≠ nghi·ªám
- Mu·ªën √≠t tham s·ªë nh·∫•t c√≥ th·ªÉ
- Nguy c∆° overfitting cao

#### Option 2: LoRA Balanced (r=16) - Khuy·∫øn ngh·ªã ch√≠nh

```python
lora_config = LoraConfig(
    r=16,                         # Rank c√¢n b·∫±ng
    lora_alpha=32,                # 2 * r
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM" ho·∫∑c "SEQ_2_SEQ_LM"
)
```

**Khi n√†o d√πng**:
- L·ª±a ch·ªçn ch√≠nh, c√¢n b·∫±ng t·ªët
- C·∫ßn hi·ªáu su·∫•t t·ªët h∆°n r=8
- Dataset ƒë·ªß ƒë·ªÉ support r=16

### Gi·∫£i Ph√°p Thay Th·∫ø: IA3 (n·∫øu d√πng Seq2Seq Model)

**Khi n√†o d√πng IA3**:
- N·∫øu s·ª≠ d·ª•ng Seq2Seq model (T5, mT5, mT0)
- C·∫ßn √≠t tham s·ªë nh·∫•t c√≥ th·ªÉ
- Mu·ªën h·ªôi t·ª• nhanh nh·∫•t

**C·∫•u h√¨nh**:
```python
from peft import IA3Config, get_peft_model

ia3_config = IA3Config(
    task_type="SEQ_2_SEQ_LM"
)
```

## K·∫ø Ho·∫°ch Th·ª±c Hi·ªán

### Phase 1: Baseline v·ªõi LoRA r=8

1. **Chu·∫©n b·ªã**:
   - Chia dataset: 80% train, 10% validation, 10% test
   - Ch·ªçn base model h·ªó tr·ª£ ti·∫øng Vi·ªát (PhoBERT, VinAI-BERT, ho·∫∑c multilingual model)
   - Format data cho training

2. **Training**:
   - LoRA r=8
   - Learning rate: 2e-4
   - Batch size: 8-16 (t√πy GPU)
   - Epochs: 5-10
   - Monitor validation loss

3. **ƒê√°nh gi√°**:
   - JSON validity rate
   - Field completeness
   - Accuracy cho is_in_scope
   - Quality c·ªßa generated text

### Phase 2: Optimization v·ªõi LoRA r=16

1. **N·∫øu Phase 1 t·ªët nh∆∞ng c·∫ßn c·∫£i thi·ªán**:
   - TƒÉng rank l√™n r=16
   - Gi·ªØ nguy√™n c√°c hyperparameters kh√°c
   - So s√°nh k·∫øt qu·∫£

2. **N·∫øu Phase 1 overfitting**:
   - Gi·∫£m learning rate
   - TƒÉng dropout
   - Th√™m regularization

### Phase 3: Fine-tuning

1. **Hyperparameter tuning**:
   - Learning rate: 1e-4 ƒë·∫øn 5e-4
   - Dropout: 0.05 ƒë·∫øn 0.2
   - Batch size: 4 ƒë·∫øn 32

2. **Target modules**:
   - Th·ª≠ ch·ªâ `["q_proj", "v_proj"]` (√≠t tham s·ªë h∆°n)
   - Th·ª≠ th√™m MLP layers n·∫øu c·∫ßn

3. **Early stopping**:
   - Monitor validation loss
   - Stop n·∫øu kh√¥ng c·∫£i thi·ªán sau 3 epochs

## L∆∞u √ù Quan Tr·ªçng

### 1. Base Model Selection

**Y√™u c·∫ßu**:
- H·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët
- C√≥ kh·∫£ nƒÉng generation t·ªët
- Ph√π h·ª£p v·ªõi structured output (JSON)
- C√≥ th·ªÉ fine-tune v·ªõi PEFT (LoRA)
- Hi·ªáu su·∫•t t·ªët v·ªõi dataset nh·ªè

#### So S√°nh Llama 3.1 8B Instruct vs Qwen 2.5 7B Instruct

D·ª±a tr√™n ph√¢n t√≠ch chi ti·∫øt trong [So s√°nh Llama 3.1 8B vs Qwen 2.5 7B](../../01_research/08_llama_8b_vs_qwen_2.5_7b.md), ƒë√¢y l√† so s√°nh cho dataset Rephrase:

| Ti√™u Ch√≠ | Llama 3.1 8B Instruct | Qwen 2.5 7B Instruct | Ph√π H·ª£p Dataset Rephrase |
|----------|----------------------|----------------------|-------------------------|
| **Structured Output** | H·ªó tr·ª£ t·ªët | **H·ªó tr·ª£ r·∫•t t·ªët (8K tokens output)** | üèÜ **Qwen** - Output d√†i h∆°n ph√π h·ª£p JSON ph·ª©c t·∫°p |
| **H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ** | ƒêa ng√¥n ng·ªØ | **29+ ng√¥n ng·ªØ, m·∫°nh v·ªõi ti·∫øng Trung/Ch√¢u √Å** | üèÜ **Qwen** - H·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët h∆°n |
| **Text Generation** | T·ªët (80.5% HumanEval) | **R·∫•t t·ªët (84.8% HumanEval)** | üèÜ **Qwen** - Code/JSON generation t·ªët h∆°n |
| **Chi ph√≠** | **$0.03/1M tokens** | $0.30/1M tokens | üèÜ **Llama** - Chi ph√≠ th·∫•p h∆°n 10 l·∫ßn |
| **T·ªëc ƒë·ªô** | **155.1 tokens/s** | 84.28 tokens/s | üèÜ **Llama** - Nhanh h∆°n 84% |
| **Time to First Token** | **0.31s** | 1.95-22.02s | üèÜ **Llama** - Ph·∫£n h·ªìi nhanh h∆°n |
| **C·ª≠a s·ªï ng·ªØ c·∫£nh** | 128K tokens | 131K tokens | ‚öñÔ∏è T∆∞∆°ng ƒë∆∞∆°ng |
| **L√Ω lu·∫≠n** | **T·ªët (GPQA 51%)** | 36.4% | üèÜ **Llama** - L√Ω lu·∫≠n t·ªët h∆°n |

#### Khuy·∫øn Ngh·ªã: Qwen 2.5 7B Instruct

**L√Ω do ch·ªçn Qwen 2.5 7B cho dataset Rephrase:**

1. **Structured Output xu·∫•t s·∫Øc:**
   - Qwen c√≥ kh·∫£ nƒÉng t·∫°o output d√†i (8K tokens) so v·ªõi Llama (4K tokens)
   - Hi·ªáu su·∫•t t·ªët h∆°n trong code generation (HumanEval 84.8% vs 80.5%)
   - Ph√π h·ª£p v·ªõi JSON generation ph·ª©c t·∫°p

2. **H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ t·ªët:**
   - H·ªó tr·ª£ 29+ ng√¥n ng·ªØ, ƒë·∫∑c bi·ªát m·∫°nh v·ªõi c√°c ng√¥n ng·ªØ Ch√¢u √Å
   - C√≥ kh·∫£ nƒÉng hi·ªÉu v√† t·∫°o text ti·∫øng Vi·ªát t·ª± nhi√™n t·ªët h∆°n
   - ƒê∆∞·ª£c train tr√™n nhi·ªÅu d·ªØ li·ªáu ƒëa ng√¥n ng·ªØ h∆°n (18T vs 15T tokens)

3. **Code/JSON Generation ch·∫•t l∆∞·ª£ng cao:**
   - Th·ª±c t·∫ø developers b√°o c√°o code generation nh·∫•t qu√°n, √≠t l·ªói
   - Ph√π h·ª£p v·ªõi structured output nh∆∞ JSON
   - Hi·ªáu su·∫•t t·ªët trong c√°c t√°c v·ª• generation ph·ª©c t·∫°p

4. **Ph√π h·ª£p v·ªõi PEFT:**
   - C·∫£ hai ƒë·ªÅu h·ªó tr·ª£ LoRA t·ªët
   - Qwen c√≥ th·ªÉ fine-tune hi·ªáu qu·∫£ v·ªõi dataset nh·ªè

**Khi n√†o ch·ªçn Llama 3.1 8B:**

- Ng√¢n s√°ch h·∫°n ch·∫ø (chi ph√≠ th·∫•p h∆°n 10 l·∫ßn)
- Y√™u c·∫ßu t·ªëc ƒë·ªô cao v√† ƒë·ªô tr·ªÖ th·∫•p
- C·∫ßn l√Ω lu·∫≠n ph·ª©c t·∫°p h∆°n
- ·ª®ng d·ª•ng production v·ªõi quy m√¥ l·ªõn

#### C√°c Model Kh√°c (Tham Kh·∫£o)

**ƒê·ªÅ xu·∫•t kh√°c**:
- **PhoBERT**: T·ªët cho ti·∫øng Vi·ªát, nh∆∞ng l√† encoder-only (c·∫ßn th√™m decoder)
- **mT5/mT0**: Multilingual, Seq2Seq, t·ªët cho generation, ph√π h·ª£p v·ªõi IA3
- **LLaMA 2/3**: T·ªët cho generation, c·∫ßn fine-tune cho ti·∫øng Vi·ªát
- **GPT-2 Vietnamese**: N·∫øu c√≥, t·ªët cho generation

**Khuy·∫øn ngh·ªã ch√≠nh**: **Qwen 2.5 7B Instruct** v·ªõi LoRA r=8 ho·∫∑c r=16

### 2. JSON Format Validation

**V·∫•n ƒë·ªÅ**: Model c√≥ th·ªÉ generate invalid JSON

**Gi·∫£i ph√°p**:
- Post-processing ƒë·ªÉ fix JSON
- JSON schema validation
- Constrained decoding n·∫øu c√≥ th·ªÉ
- Training v·ªõi JSON examples r√µ r√†ng

### 3. Class Imbalance

**V·∫•n ƒë·ªÅ**: 96.1% in-scope vs 3.9% out-of-scope

**Gi·∫£i ph√°p**:
- Weighted loss function
- Oversampling out-of-scope samples
- Focal loss ƒë·ªÉ focus v√†o hard examples
- Stratified sampling trong train/val/test split

### 4. Empty Fields Handling

**V·∫•n ƒë·ªÅ**: 
- In-scope: `reasoning` th∆∞·ªùng r·ªóng
- Out-of-scope: `keyword` v√† `message_banner` r·ªóng

**Gi·∫£i ph√°p**:
- Training v·ªõi explicit empty string examples
- Special token cho empty fields
- Post-processing ƒë·ªÉ ƒë·∫£m b·∫£o pattern ƒë√∫ng

### 5. Vietnamese Language

**V·∫•n ƒë·ªÅ**: Model c·∫ßn hi·ªÉu v√† t·∫°o text ti·∫øng Vi·ªát t·ª± nhi√™n

**Gi·∫£i ph√°p**:
- Ch·ªçn model ƒë√£ ƒë∆∞·ª£c pretrain tr√™n ti·∫øng Vi·ªát
- Fine-tune v·ªõi Vietnamese dataset n·∫øu c·∫ßn
- Ki·ªÉm tra ch·∫•t l∆∞·ª£ng text generation

## Metrics ƒê√°nh Gi√°

### 1. JSON Validity
- T·ª∑ l·ªá output l√† valid JSON
- Target: >95%

### 2. Field Completeness
- T·ª∑ l·ªá c√°c tr∆∞·ªùng ƒë∆∞·ª£c ƒëi·ªÅn ƒë·∫ßy ƒë·ªß
- Target: >98%

### 3. is_in_scope Accuracy
- ƒê·ªô ch√≠nh x√°c ph√¢n lo·∫°i in-scope/out-of-scope
- Target: >90% (c·∫£ hai classes)

### 4. Text Quality
- BLEU/ROUGE score cho keyword v√† messages
- Human evaluation cho naturalness

### 5. Consistency
- Keyword li√™n quan ƒë·∫øn query
- Message tone v√† style nh·∫•t qu√°n

## K·∫øt Lu·∫≠n

### Gi·∫£i Ph√°p T·ªëi ∆Øu

**Ph∆∞∆°ng ph√°p PEFT**: **LoRA v·ªõi r=8 ho·∫∑c r=16**

**Base Model**: **Qwen 2.5 7B Instruct** (khuy·∫øn ngh·ªã ch√≠nh) ho·∫∑c **Llama 3.1 8B Instruct** (n·∫øu ng√¢n s√°ch h·∫°n ch·∫ø)

### L√Ω Do Ch·ªçn LoRA

1. **Ph√π h·ª£p dataset nh·ªè (1K samples)**:
   - V·ªõi r=8: ~0.13% tham s·ªë (ph√π h·ª£p 1K samples)
   - V·ªõi r=16: ~0.26% tham s·ªë (v·∫´n an to√†n cho 1K samples)
   - C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh rank d·ªÖ d√†ng

2. **Nhanh v√† hi·ªáu qu·∫£**:
   - H·ªôi t·ª• nhanh (5-10 epochs)
   - Kh√¥ng c·∫ßn nhi·ªÅu epochs nh∆∞ prompt-based methods
   - Ti·∫øt ki·ªám th·ªùi gian v√† t√†i nguy√™n

3. **T·ªët cho text generation v√† structured output**:
   - LoRA ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët cho generation tasks
   - C√≥ th·ªÉ handle structured output (JSON)
   - ƒê∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i cho c√°c t√°c v·ª• t∆∞∆°ng t·ª±

4. **·ªîn ƒë·ªãnh v√† ƒë∆∞·ª£c h·ªó tr·ª£**:
   - Nhi·ªÅu t√†i li·ªáu v√† v√≠ d·ª•
   - C·ªông ƒë·ªìng h·ªó tr·ª£ t·ªët
   - D·ªÖ debug v√† troubleshoot

5. **Linh ho·∫°t**:
   - C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh rank d·ª±a tr√™n k·∫øt qu·∫£
   - C√≥ th·ªÉ th·ª≠ nghi·ªám v·ªõi c√°c target_modules kh√°c nhau
   - D·ªÖ d√†ng fine-tune hyperparameters

### L√Ω Do Ch·ªçn Qwen 2.5 7B Instruct

1. **Structured Output xu·∫•t s·∫Øc**:
   - Kh·∫£ nƒÉng t·∫°o output d√†i (8K tokens) ph√π h·ª£p v·ªõi JSON ph·ª©c t·∫°p
   - Hi·ªáu su·∫•t t·ªët trong code/JSON generation (HumanEval 84.8%)

2. **H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ t·ªët**:
   - 29+ ng√¥n ng·ªØ, ƒë·∫∑c bi·ªát m·∫°nh v·ªõi ti·∫øng Vi·ªát v√† c√°c ng√¥n ng·ªØ Ch√¢u √Å
   - Hi·ªÉu v√† t·∫°o text ti·∫øng Vi·ªát t·ª± nhi√™n t·ªët h∆°n

3. **Code/JSON Generation ch·∫•t l∆∞·ª£ng cao**:
   - Developers b√°o c√°o code generation nh·∫•t qu√°n, √≠t l·ªói
   - Ph√π h·ª£p v·ªõi structured output nh∆∞ JSON

4. **Ph√π h·ª£p v·ªõi PEFT**:
   - H·ªó tr·ª£ LoRA t·ªët
   - Fine-tune hi·ªáu qu·∫£ v·ªõi dataset nh·ªè

### K·∫ø Ho·∫°ch Th·ª±c Hi·ªán

**Phase 1: Baseline**
1. Base Model: **Qwen 2.5 7B Instruct**
2. PEFT Method: **LoRA r=8**
3. Learning rate: 2e-4
4. Batch size: 8-16
5. Epochs: 5-10

**Phase 2: Optimization**
1. N·∫øu Phase 1 t·ªët: N√¢ng c·∫•p l√™n **LoRA r=16**
2. N·∫øu overfitting: Gi·∫£m learning rate, tƒÉng dropout
3. Fine-tune hyperparameters d·ª±a tr√™n k·∫øt qu·∫£

**Phase 3: Production**
1. X·ª≠ l√Ω class imbalance v√† JSON validation
2. T·ªëi ∆∞u h√≥a inference speed
3. Deploy v√† monitor

### Gi·∫£i Ph√°p Thay Th·∫ø

**N·∫øu ng√¢n s√°ch h·∫°n ch·∫ø**: **Llama 3.1 8B Instruct**
- Chi ph√≠ th·∫•p h∆°n 10 l·∫ßn ($0.03 vs $0.30/1M tokens)
- T·ªëc ƒë·ªô nhanh h∆°n (155.1 vs 84.28 tokens/s)
- V·∫´n ƒë·∫°t hi·ªáu su·∫•t t·ªët cho structured output

**N·∫øu s·ª≠ d·ª•ng Seq2Seq model**: **IA3**
- √çt tham s·ªë nh·∫•t (~0.02%)
- H·ªôi t·ª• nhanh nh·∫•t
- Ph√π h·ª£p v·ªõi mT5/mT0

## T√†i Li·ªáu Tham Kh·∫£o

- [Dataset Analysis](./01_rephrase.md)
- [PEFT Method Selection Guide](./02_peft_method_selection_guide.md)
- [LoRA Methods Guide](../01_research/04_peft_method_lora_method.md)
- [IA3 Guide](../01_research/05_peft_method_ia3.md)
- [Prompt-based Methods Guide](../01_research/03_peft_method_prompt_base.md)
- [So s√°nh Llama 3.1 8B vs Qwen 2.5 7B](../01_research/08_llama_8b_vs_qwen_2.5_7b.md)

