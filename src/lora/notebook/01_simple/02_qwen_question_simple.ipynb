{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple Q&A with Qwen 7B\n",
        "\n",
        "Notebook n√†y h∆∞·ªõng d·∫´n load v√† s·ª≠ d·ª•ng Qwen 7B model ƒë·ªÉ th·ª±c hi·ªán Q&A ƒë∆°n gi·∫£n.\n",
        "\n",
        "## Th√¥ng tin\n",
        "- **Model**: Qwen/Qwen2.5-7B-Instruct\n",
        "- **Task**: Question Answering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒêang ki·ªÉm tra v√† c√†i ƒë·∫∑t dependencies...\n",
            "\n",
            "Python version: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:29:10) [GCC 14.3.0]\n",
            "‚ö† torch ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. ƒêang c√†i ƒë·∫∑t...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mcheck_and_install\u001b[0;34m(package_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t (version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m package \u001b[38;5;129;01min\u001b[39;00m packages:\n\u001b[0;32m---> 76\u001b[0m         \u001b[43mcheck_and_install\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Verify bitsandbytes after installation\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "Cell \u001b[0;32mIn[1], line 35\u001b[0m, in \u001b[0;36mcheck_and_install\u001b[0;34m(package_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcheck_call([\n\u001b[1;32m     30\u001b[0m         sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--upgrade\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchaudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--index-url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/whl/cu118\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m     ])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--upgrade\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úì \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/venv/main/lib/python3.10/subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[1;32m    366\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/venv/main/lib/python3.10/subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
            "File \u001b[0;32m/venv/main/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/venv/main/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
            "File \u001b[0;32m/venv/main/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Install dependencies (ch·∫°y cell n√†y tr∆∞·ªõc n·∫øu ch∆∞a c√†i ƒë·∫∑t)\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def check_and_install(package_name):\n",
        "    \"\"\"Ki·ªÉm tra v√† c√†i ƒë·∫∑t package n·∫øu ch∆∞a c√≥\"\"\"\n",
        "    package_import = package_name.split('>=')[0].split('==')[0].split('<')[0].strip()\n",
        "    \n",
        "    # ƒê·∫∑c bi·ªát x·ª≠ l√Ω torch - c√≥ th·ªÉ c√≥ l·ªói compatibility v·ªõi Python 3.12\n",
        "    if package_import == \"torch\":\n",
        "        try:\n",
        "            import torch\n",
        "            print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t (version: {torch.__version__})\")\n",
        "            return True\n",
        "        except (ImportError, ValueError) as e:\n",
        "            if isinstance(e, ValueError) and (\"METH_CLASS\" in str(e) or \"METH_STATIC\" in str(e)):\n",
        "                print(f\"‚ö† {package_name} c√≥ v·∫•n ƒë·ªÅ compatibility v·ªõi Python {sys.version_info.major}.{sys.version_info.minor}\")\n",
        "                print(\"   ‚ö†Ô∏è L·ªñI: PyTorch kh√¥ng t∆∞∆°ng th√≠ch!\")\n",
        "                print(\"   üí° Gi·∫£i ph√°p: Ch·∫°y cell ti·∫øp theo (cell fix PyTorch) ƒë·ªÉ c√†i ƒë·∫∑t l·∫°i PyTorch\")\n",
        "                print(\"   Ho·∫∑c ch·∫°y l·ªánh sau trong terminal:\")\n",
        "                print(\"   !pip uninstall -y torch torchvision torchaudio\")\n",
        "                print(\"   !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
        "                raise ValueError(\"PyTorch kh√¥ng t∆∞∆°ng th√≠ch. Vui l√≤ng ch·∫°y cell fix PyTorch tr∆∞·ªõc.\")\n",
        "            else:\n",
        "                print(f\"‚ö† {package_name} ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. ƒêang c√†i ƒë·∫∑t...\")\n",
        "                # C√†i ƒë·∫∑t PyTorch t∆∞∆°ng th√≠ch v·ªõi Python 3.12\n",
        "                if sys.version_info >= (3, 12):\n",
        "                    subprocess.check_call([\n",
        "                        sys.executable, \"-m\", \"pip\", \"install\", \n",
        "                        \"--upgrade\", \"torch\", \"torchvision\", \"torchaudio\", \n",
        "                        \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
        "                    ])\n",
        "                else:\n",
        "                    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package_name])\n",
        "                print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
        "                return False\n",
        "    elif package_import == \"bitsandbytes\":\n",
        "        # ƒê·∫∑c bi·ªát x·ª≠ l√Ω bitsandbytes - c·∫ßn upgrade ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch\n",
        "        try:\n",
        "            import bitsandbytes as bnb\n",
        "            print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t (version: {bnb.__version__})\")\n",
        "            # Ki·ªÉm tra xem c√≥ th·ªÉ import ƒë∆∞·ª£c kh√¥ng\n",
        "            from transformers import BitsAndBytesConfig\n",
        "            print(\"   ‚úì BitsAndBytesConfig c√≥ th·ªÉ s·ª≠ d·ª•ng\")\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(f\"‚ö† {package_name} ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. ƒêang c√†i ƒë·∫∑t...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package_name])\n",
        "            print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
        "            return False\n",
        "    else:\n",
        "        # X·ª≠ l√Ω c√°c package kh√°c\n",
        "        try:\n",
        "            __import__(package_import)\n",
        "            print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(f\"‚ö† {package_name} ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. ƒêang c√†i ƒë·∫∑t...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "            print(f\"‚úì {package_name} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
        "            return False\n",
        "\n",
        "print(\"ƒêang ki·ªÉm tra v√† c√†i ƒë·∫∑t dependencies...\\n\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "packages = [\n",
        "    \"torch\",\n",
        "    \"transformers>=4.35.0\",\n",
        "    \"accelerate>=0.24.0\",\n",
        "    \"bitsandbytes>=0.41.0\",  # C·∫ßn cho quantization\n",
        "]\n",
        "\n",
        "try:\n",
        "    for package in packages:\n",
        "        check_and_install(package)\n",
        "    \n",
        "    # Verify bitsandbytes after installation\n",
        "    try:\n",
        "        from transformers import BitsAndBytesConfig\n",
        "        print(\"\\n‚úì BitsAndBytesConfig s·∫µn s√†ng cho quantization\")\n",
        "    except ImportError:\n",
        "        print(\"\\n‚ö† BitsAndBytesConfig ch∆∞a s·∫µn s√†ng - c√≥ th·ªÉ c·∫ßn restart kernel\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚úì T·∫•t c·∫£ dependencies ƒë√£ s·∫µn s√†ng!\")\n",
        "    print(\"=\"*50)\n",
        "except ValueError as e:\n",
        "    if \"PyTorch\" in str(e):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"‚ùå PyTorch kh√¥ng t∆∞∆°ng th√≠ch!\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"\\nVui l√≤ng:\")\n",
        "        print(\"1. Ch·∫°y cell ti·∫øp theo (cell 'Fix PyTorch compatibility')\")\n",
        "        print(\"2. Sau ƒë√≥ restart kernel\")\n",
        "        print(\"3. Ch·∫°y l·∫°i cell n√†y\")\n",
        "    else:\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 1: Import th∆∞ vi·ªán\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# Ki·ªÉm tra GPU\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"CUDA memory free: {torch.cuda.get_device_properties(0).total_memory / 1e9 - torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"S·ª≠ d·ª•ng CPU\")\n",
        "\n",
        "# H√†m ƒë·ªÉ clear GPU memory\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"X√≥a cache GPU ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        print(\"‚úì ƒê√£ x√≥a GPU cache\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 2: Load Model v√† Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "# C·∫•u h√¨nh quantization ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ\n",
        "# S·ª≠ d·ª•ng 4-bit quantization ƒë·ªÉ gi·∫£m memory usage t·ª´ ~14GB xu·ªëng ~4-5GB\n",
        "use_quantization = True  # ƒê·∫∑t False n·∫øu c√≥ ƒë·ªß VRAM (>16GB)\n",
        "\n",
        "# Ki·ªÉm tra bitsandbytes tr∆∞·ªõc khi s·ª≠ d·ª•ng quantization\n",
        "bitsandbytes_available = False\n",
        "if use_quantization and torch.cuda.is_available():\n",
        "    try:\n",
        "        from transformers import BitsAndBytesConfig\n",
        "        import bitsandbytes as bnb\n",
        "        bitsandbytes_available = True\n",
        "        print(\"‚ö†Ô∏è S·ª≠ d·ª•ng 4-bit quantization ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ\")\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "    except (ImportError, ModuleNotFoundError) as e:\n",
        "        print(\"‚ö†Ô∏è bitsandbytes kh√¥ng kh·∫£ d·ª•ng - t·∫Øt quantization\")\n",
        "        print(f\"   L·ªói: {e}\")\n",
        "        print(\"   üí° Ch·∫°y cell 'Fix bitsandbytes installation' ƒë·ªÉ c√†i ƒë·∫∑t l·∫°i\")\n",
        "        print(\"   Ho·∫∑c ƒë·∫∑t use_quantization = False ƒë·ªÉ ti·∫øp t·ª•c kh√¥ng d√πng quantization\")\n",
        "        use_quantization = False\n",
        "        quantization_config = None\n",
        "        bitsandbytes_available = False\n",
        "else:\n",
        "    quantization_config = None\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"‚ö†Ô∏è Kh√¥ng s·ª≠ d·ª•ng quantization (kh√¥ng c√≥ CUDA)\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Kh√¥ng s·ª≠ d·ª•ng quantization (c·∫ßn nhi·ªÅu VRAM)\")\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# ƒê·∫£m b·∫£o c√≥ pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(\"Loading model...\")\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=quantization_config,\n",
        "        torch_dtype=torch.float16 if (torch.cuda.is_available() and not use_quantization) else None,\n",
        "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    # Move to device if not using device_map\n",
        "    if not torch.cuda.is_available():\n",
        "        model = model.to(\"cpu\")\n",
        "    \n",
        "    print(f\"‚úì Model loaded: {model_name}\")\n",
        "    \n",
        "    # Device detection\n",
        "    if hasattr(model, 'hf_device_map') and model.hf_device_map:\n",
        "        devices = set(model.hf_device_map.values())\n",
        "        print(f\"‚úì Model devices: {', '.join(sorted(devices))}\")\n",
        "    else:\n",
        "        print(f\"‚úì Model device: {next(model.parameters()).device}\")\n",
        "    \n",
        "    # Ki·ªÉm tra memory usage\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "        reserved = torch.cuda.memory_reserved(0) / 1e9\n",
        "        print(f\"‚úì GPU memory allocated: {allocated:.2f} GB\")\n",
        "        print(f\"‚úì GPU memory reserved: {reserved:.2f} GB\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    if \"bitsandbytes\" in str(e).lower():\n",
        "        print(\"‚ùå Error: bitsandbytes ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c c√≥ v·∫•n ƒë·ªÅ\")\n",
        "        print(\"\\nüí° Gi·∫£i ph√°p:\")\n",
        "        print(\"1. Ch·∫°y cell 'Fix bitsandbytes installation' (cell tr∆∞·ªõc ƒë√≥)\")\n",
        "        print(\"2. Restart kernel\")\n",
        "        print(\"3. Ch·∫°y l·∫°i cell n√†y\")\n",
        "        print(\"\\nHo·∫∑c t·∫Øt quantization b·∫±ng c√°ch:\")\n",
        "        print(\"   - ƒê·∫∑t use_quantization = False ·ªü ƒë·∫ßu cell n√†y\")\n",
        "        print(\"   - Ch·∫°y l·∫°i cell\")\n",
        "        raise\n",
        "    else:\n",
        "        raise\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")\n",
        "    if use_quantization and \"bitsandbytes\" in str(e).lower():\n",
        "        print(\"\\nüí° Gi·∫£i ph√°p:\")\n",
        "        print(\"1. Ch·∫°y cell 'Fix bitsandbytes installation'\")\n",
        "        print(\"2. Restart kernel\")\n",
        "        print(\"3. Ch·∫°y l·∫°i cell n√†y\")\n",
        "        print(\"\\nHo·∫∑c t·∫Øt quantization:\")\n",
        "        print(\"   - ƒê·∫∑t use_quantization = False ·ªü ƒë·∫ßu cell n√†y\")\n",
        "        print(\"   - Ch·∫°y l·∫°i cell\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è N·∫øu g·∫∑p l·ªói bitsandbytes\n",
        "\n",
        "N·∫øu g·∫∑p l·ªói v·ªÅ bitsandbytes khi load model, ch·∫°y cell d∆∞·ªõi ƒë√¢y ƒë·ªÉ c√†i ƒë·∫∑t l·∫°i:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Fix bitsandbytes installation\n",
        "# Ch·∫°y cell n√†y n·∫øu g·∫∑p l·ªói ImportError v·ªÅ bitsandbytes\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"ƒêang c√†i ƒë·∫∑t l·∫°i bitsandbytes...\")\n",
        "\n",
        "# Uninstall old version\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"bitsandbytes\"])\n",
        "    print(\"‚úì ƒê√£ g·ª° c√†i ƒë·∫∑t bitsandbytes c≈©\")\n",
        "except:\n",
        "    print(\"‚ö† Kh√¥ng t√¨m th·∫•y bitsandbytes c≈© ƒë·ªÉ g·ª° c√†i ƒë·∫∑t\")\n",
        "\n",
        "# Install latest version\n",
        "print(\"\\nƒêang c√†i ƒë·∫∑t bitsandbytes m·ªõi nh·∫•t...\")\n",
        "subprocess.check_call([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \n",
        "    \"--upgrade\", \"--no-cache-dir\", \"bitsandbytes>=0.41.0\"\n",
        "])\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    import bitsandbytes as bnb\n",
        "    print(f\"\\n‚úì bitsandbytes ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng!\")\n",
        "    print(f\"  Version: {bnb.__version__}\")\n",
        "    \n",
        "    # Test BitsAndBytesConfig\n",
        "    from transformers import BitsAndBytesConfig\n",
        "    print(\"  ‚úì BitsAndBytesConfig c√≥ th·ªÉ s·ª≠ d·ª•ng\")\n",
        "    \n",
        "    # Test basic functionality\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  ‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "        print(\"  ‚úì bitsandbytes s·∫µn s√†ng cho quantization\")\n",
        "    else:\n",
        "        print(\"  ‚ö† CUDA kh√¥ng available - quantization c√≥ th·ªÉ kh√¥ng ho·∫°t ƒë·ªông\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå L·ªói khi verify bitsandbytes: {e}\")\n",
        "    print(\"\\nTh·ª≠ restart kernel v√† ch·∫°y l·∫°i cell n√†y.\")\n",
        "    print(\"N·∫øu v·∫´n l·ªói, c√≥ th·ªÉ t·∫Øt quantization b·∫±ng c√°ch ƒë·∫∑t use_quantization = False\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 3: H√†m Q&A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "def ask_question(question: str, max_new_tokens: int = 512, temperature: float = 0.7):\n",
        "    \"\"\"\n",
        "    H√†m ƒë·ªÉ h·ªèi ƒë√°p v·ªõi model (t·ªëi ∆∞u memory)\n",
        "    \n",
        "    Args:\n",
        "        question: C√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi\n",
        "        max_new_tokens: S·ªë token t·ªëi ƒëa ƒë·ªÉ generate (gi·∫£m n·∫øu h·∫øt memory)\n",
        "        temperature: Nhi·ªát ƒë·ªô cho sampling (0.0-1.0)\n",
        "    \"\"\"\n",
        "    # Clear cache tr∆∞·ªõc khi generate\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # Format prompt cho Qwen Instruct model\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    \n",
        "    # Apply chat template\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    \n",
        "    # Tokenize\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "    \n",
        "    # Generate v·ªõi c√°c t√πy ch·ªçn t·ªëi ∆∞u memory\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                **model_inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=True if temperature > 0 else False,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                # T·ªëi ∆∞u memory\n",
        "                use_cache=True,  # S·ª≠ d·ª•ng KV cache ƒë·ªÉ tƒÉng t·ªëc\n",
        "            )\n",
        "    except torch.cuda.OutOfMemoryError as e:\n",
        "        print(f\"‚ö†Ô∏è Out of Memory! ƒêang th·ª≠ v·ªõi max_new_tokens nh·ªè h∆°n...\")\n",
        "        # Clear cache v√† th·ª≠ l·∫°i v·ªõi max_new_tokens nh·ªè h∆°n\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        # Th·ª≠ l·∫°i v·ªõi max_new_tokens gi·∫£m ƒëi m·ªôt n·ª≠a\n",
        "        new_max_tokens = max_new_tokens // 2\n",
        "        if new_max_tokens < 50:\n",
        "            raise RuntimeError(\"Kh√¥ng ƒë·ªß memory ngay c·∫£ v·ªõi max_new_tokens nh·ªè nh·∫•t. H√£y s·ª≠ d·ª•ng quantization ho·∫∑c gi·∫£m k√≠ch th∆∞·ªõc model.\")\n",
        "        \n",
        "        print(f\"Th·ª≠ l·∫°i v·ªõi max_new_tokens={new_max_tokens}\")\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                **model_inputs,\n",
        "                max_new_tokens=new_max_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=True if temperature > 0 else False,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "            )\n",
        "    \n",
        "    # Decode response\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "    \n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    \n",
        "    # Clear cache sau khi generate\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return response\n",
        "\n",
        "print(\"‚úì H√†m ask_question ƒë√£ s·∫µn s√†ng!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B∆∞·ªõc 4: Test Q&A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Test v·ªõi m·ªôt s·ªë c√¢u h·ªèi ƒë∆°n gi·∫£n\n",
        "test_questions = [\n",
        "    \"Xin ch√†o! B·∫°n l√† ai?\",\n",
        "    \"Python l√† g√¨?\",\n",
        "    \"Gi·∫£i th√≠ch ng·∫Øn g·ªçn v·ªÅ machine learning\",\n",
        "]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TESTING Q&A\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n[{i}] C√¢u h·ªèi: {question}\")\n",
        "    print(\"-\" * 60)\n",
        "    answer = ask_question(question)\n",
        "    print(f\"Tr·∫£ l·ªùi: {answer}\")\n",
        "    print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S·ª≠ d·ª•ng t√πy ch·ªânh\n",
        "\n",
        "B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m `ask_question()` v·ªõi b·∫•t k·ª≥ c√¢u h·ªèi n√†o:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Th·ª≠ v·ªõi c√¢u h·ªèi c·ªßa b·∫°n\n",
        "my_question = \"\"\"\n",
        "# H∆Ø·ªöNG D·∫™N H·ªÜ TH·ªêNG\n",
        "B·∫°n l√† chuy√™n gia t·ªëi ∆∞u t·ª´ kh√≥a t√¨m ki·∫øm s·∫£n ph·∫©m cho Concung(m·ªôt chu·ªói si√™u th·ªã m·∫π v√† b√© l·ªõn nh·∫•t t·∫°i Vi·ªát Nam). Nhi·ªám v·ª• c·ªßa b·∫°n l√† bi·∫øn ƒë·ªïi c√¢u h·ªèi c·ªßa kh√°ch h√†ng th√†nh t·ª´ kh√≥a t√¨m ki·∫øm hi·ªáu qu·∫£ nh·∫•t v√† t·∫°o message banner th√¢n thi·ªán.\n",
        "\n",
        "# NHI·ªÜM V·ª§ CH√çNH\n",
        "1.  **T·ªëi ∆∞u h√≥a T·ª´ kh√≥a t√¨m ki·∫øm (`keyword`):** Chuy·ªÉn ƒë·ªïi `USER_QUERY` th√†nh t·ª´ kh√≥a t√¨m ki·∫øm ng·∫Øn g·ªçn, ch√≠nh x√°c v√† hi·ªáu qu·∫£ nh·∫•t cho h·ªá th·ªëng c·ªßa Concung.\n",
        "2.  **T·∫°o Tin nh·∫Øn Banner (`message_banner`):** So·∫°n m·ªôt tin nh·∫Øn banner th√¢n thi·ªán ƒë·ªÉ x√°c nh·∫≠n ƒë√£ hi·ªÉu y√™u c·∫ßu c·ªßa kh√°ch h√†ng.\n",
        "3.  **T·∫°o Tin nh·∫Øn D·ª± ph√≤ng (`message_no_result`):** So·∫°n m·ªôt tin nh·∫Øn d·ª± ph√≤ng ƒë∆∞·ª£c c√° nh√¢n h√≥a trong tr∆∞·ªùng h·ª£p kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m, gi√∫p gi·ªØ ch√¢n kh√°ch h√†ng v√† g·ª£i √Ω c·∫£i thi·ªán t√¨m ki·∫øm.\n",
        "\n",
        "# QUY T·∫ÆC PH·∫†M VI X·ª¨ L√ù (QUAN TR·ªåNG)\n",
        "## is_in_scope = true khi QUERY th·ªèa m√£n T·∫§T C·∫¢ ƒëi·ªÅu ki·ªán sau:\n",
        "1.  **Li√™n quan ƒë·∫øn h·ªá sinh th√°i Con C∆∞ng**: QUERY ƒë·ªÅ c·∫≠p ƒë·∫øn m·ªôt trong c√°c ch·ªß ƒë·ªÅ sau:\n",
        "    *   **T√¨m ki·∫øm s·∫£n ph·∫©m**: T√¨m ki·∫øm, mua s·∫Øm, ho·∫∑c so s√°nh s·∫£n ph·∫©m (v√≠ d·ª•: \"s·ªØa cho b√©\", \"t√£ Huggies\", \"kem ch·ªëng hƒÉm\").\n",
        "    *   **Th√¥ng tin & H∆∞·ªõng d·∫´n**: C√°c b√†i vi·∫øt, c·∫©m nang, ho·∫∑c m·∫πo li√™n quan ƒë·∫øn m·∫π, b√©, v√† gia ƒë√¨nh (v√≠ d·ª•: \"c√°ch chƒÉm s√≥c tr·∫ª s∆° sinh\", \"th·ª±c ƒë∆°n ƒÉn d·∫∑m\", \"b√≠ quy·∫øt gi√∫p m·∫π b·∫ßu ƒë√≥n T·∫øt an to√†n\", \"b·ªánh vi·ªán ph·ª• s·∫£n uy t√≠n\").\n",
        "    *   **Th√¥ng tin v·ªÅ Con C∆∞ng**: C√°c ch√≠nh s√°ch, ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i, ho·∫∑c th√¥ng tin v·ªÅ c√¥ng ty (v√≠ d·ª•: \"ch√≠nh s√°ch ƒë·ªïi tr·∫£\", \"khuy·∫øn m√£i th√°ng 10\", \"giao h√†ng\", \"giao nh·∫≠n\").\n",
        "2.  **H·ª£p ph√°p**: N·ªôi dung kh√¥ng vi ph·∫°m ph√°p lu·∫≠t Vi·ªát Nam.\n",
        "3.  **Kh√¥ng ƒë·ªôc h·∫°i**: Kh√¥ng ch·ª©a n·ªôi dung ph·∫£n c·∫£m, th√¥ t·ª•c, c√≥ h·∫°i.\n",
        "\n",
        "## is_in_scope = false khi QUERY thu·ªôc m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau:\n",
        "- **Kh√¥ng li√™n quan ƒë·∫øn h·ªá sinh th√°i Con C∆∞ng**: C√°c c√¢u h·ªèi ki·∫øn th·ª©c t·ªïng qu√°t kh√¥ng li√™n quan ƒë·∫øn m·∫π, b√© v√† gia ƒë√¨nh (v√≠ d·ª•: \"th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨\", \"k·∫øt qu·∫£ x·ªï s·ªë\"), tin t·ª©c kh√¥ng li√™n quan.\n",
        "- **N·ªôi dung ƒë·ªôc h·∫°i**: Th√¥ t·ª•c, ph·∫£n c·∫£m, k√≠ch ƒë·ªông b·∫°o l·ª±c, ph√¢n bi·ªát ch·ªßng t·ªôc.\n",
        "- **Ch√≠nh tr·ªã**: Quan ƒëi·ªÉm ch√≠nh tr·ªã, ·ª©ng vi√™n, ch√≠nh s√°ch, b·∫ßu c·ª≠.\n",
        "- **B·∫•t h·ª£p ph√°p**: Vi ph·∫°m ph√°p lu·∫≠t, ma t√∫y, v≈© kh√≠, h√†ng c·∫•m.\n",
        "- **So s√°nh ƒë·ªëi th·ªß**: So s√°nh tr·ª±c ti·∫øp Con C∆∞ng v·ªõi c√°c n·ªÅn t·∫£ng kh√°c (v√≠ d·ª•: \"gi√° ·ªü Shopee r·∫ª h∆°n ph·∫£i kh√¥ng\").\n",
        "- **T·∫•n c√¥ng danh ti·∫øng**: Ph·ªâ b√°ng c√° nh√¢n, doanh nghi·ªáp.\n",
        "\n",
        "# QUY T·∫ÆC T·ªêI ∆ØU T·ª™ KH√ìA (CH·ªà KHI is_in_scope = true)\n",
        "## 1. Ph√¢n T√≠ch √ù ƒê·ªãnh\n",
        "- X√°c ƒë·ªãnh nhu c·∫ßu s·∫£n ph·∫©m c·ªët l√µi t·ª´ c√¢u h·ªèi kh√°ch h√†ng\n",
        "- ∆Øu ti√™n c√°c nh√≥m s·∫£n ph·∫©m ch·ªß l·ª±c: m·∫π v√† b√©, th·ªùi trang, ƒëi·ªán t·ª≠, gia d·ª•ng, th·ª±c ph·∫©m\n",
        "\n",
        "## 2. X√¢y D·ª±ng T·ª´ Kh√≥a\n",
        "- **X·ª≠ L√Ω Truy V·∫•n V·ªÅ Th∆∞∆°ng Hi·ªáu Con C∆∞ng**: N·∫øu `USER_QUERY` ch·ªâ l√† \"Con C∆∞ng\" (ho·∫∑c c√°c bi·∫øn th·ªÉ vi·∫øt kh√¥ng d·∫•u/sai ch√≠nh t·∫£ nh∆∞ \"concung\", \"con cung\"), `keyword` ph·∫£i l√† \"Gi·ªõi thi·ªáu Con C∆∞ng\".\n",
        "- S·ª≠ d·ª•ng t√™n s·∫£n ph·∫©m c·ª• th·ªÉ, kh√¥ng d√πng m√¥ t·∫£ chung chung\n",
        "- Bao g·ªìm thu·ªôc t√≠nh li√™n quan: ƒë·ªô tu·ªïi, th∆∞∆°ng hi·ªáu, lo·∫°i, ch·ª©c nƒÉng, k√≠ch th∆∞·ªõc\n",
        "- ∆Øu ti√™n t√™n s·∫£n ph·∫©m h∆°n m√¥ t·∫£ v·∫•n ƒë·ªÅ\n",
        "- T·ªëi ƒëa 20 t·ª´\n",
        "- S·ª≠ d·ª•ng thu·∫≠t ng·ªØ ti·∫øng Vi·ªát ph√π h·ª£p v·ªõi th·ªã tr∆∞·ªùng Vi·ªát Nam\n",
        "  - **S·ª¨ D·ª§NG CONCUNG_SUGGESTIONS (CH·ªà 2 TR∆Ø·ªú·ªúNG H·ª¢P)**:\n",
        "  - **QUY T·∫ÆC NGHI√äM NG·∫∂T (√ÅP D·ª§NG CHO C·∫¢ 2 TR∆Ø·ªú·ªúNG H·ª¢P)**:\n",
        "      - **QUAN TR·ªåNG**: N·∫æU `USER_QUERY` C√ì T·ª™ 2 T·ª™ TR·ªû L√äN V√Ä ƒê√É R√ï NGHƒ®A, B·ªé QUA `CONCUNG_SUGGESTIONS` (tr·ª´ tr∆∞·ªùng h·ª£p 2: s·ª≠a l·ªói ch√≠nh t·∫£ th∆∞∆°ng hi·ªáu).\n",
        "      - KH√îNG copy tr·ª±c ti·∫øp c√°c c·ª•m t·ª´ t·ª´ CONCUNG_SUGGESTIONS v√†o keyword\n",
        "      - CH·ªà d√πng CONCUNG_SUGGESTIONS ƒë·ªÉ hi·ªÉu ng√†nh h√†ng/lo·∫°i s·∫£n ph·∫©m, sau ƒë√≥ t·∫°o keyword\n",
        "      - GI·ªÆ NGUY√äN t·ª´ kh√≥a g·ªëc t·ª´ QUERY (bao g·ªìm t√™n th∆∞∆°ng hi·ªáu n·∫øu c√≥)\n",
        "      - B·ªî SUNG th√¥ng tin lo·∫°i s·∫£n ph·∫©m chung chung v√†o keyword (v√≠ d·ª•: \"s·ªØa\", \"t√£\", \"qu·∫ßn √°o\"), kh√¥ng ph·∫£i c√°c bi·∫øn th·ªÉ chi ti·∫øt.\n",
        "      - KH√îNG s·ª≠ d·ª•ng CONCUNG_SUGGESTIONS cho message_banner\n",
        "  - **Tr∆∞·ªùng h·ª£p 1 ‚Äî Keyword ng·∫Øn/kh√¥ng r√µ**: Khi QUERY ch·ªâ c√≥ 1 t·ª´ v√† ho√†n to√†n m∆° h·ªì, kh√¥ng ƒëo√°n ƒë∆∞·ª£c lo·∫°i s·∫£n ph·∫©m.\n",
        "    - **ƒêI·ªÄU KI·ªÜN S·ª¨ D·ª§NG**: CH·ªà khi QUERY = 1 t·ª´ V√Ä kh√¥ng th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c ng√†nh h√†ng/lo·∫°i s·∫£n ph·∫©m\n",
        "    - **M·ª§C ƒê√çCH DUY NH·∫§T**: D√πng CONCUNG_SUGGESTIONS ƒë·ªÉ x√°c ƒë·ªãnh ng√†nh h√†ng/lo·∫°i s·∫£n ph·∫©m trong c·ª≠a h√†ng Concung\n",
        "    - **V√≠ d·ª•**:\n",
        "      - QUERY \"nan\" + CONCUNG_SUGGESTIONS \"s·ªØa nan, nan 2, nan 3\" ‚Üí Ph√¢n t√≠ch: ng√†nh h√†ng = s·ªØa ‚Üí Keyword \"s·ªØa nan cho b√©\"\n",
        "      - QUERY \"milo\" + CONCUNG_SUGGESTIONS \"milo 3in1, milo √∫c\" ‚Üí Ph√¢n t√≠ch: ng√†nh h√†ng = s·ªØa ‚Üí Keyword \"s·ªØa milo\"\n",
        "      - QUERY \"animo\" ‚Üí Ph√¢n t√≠ch: animo l√† th∆∞∆°ng hi·ªáu ƒë·ªôc quy·ªÅn c·ªßa Concung ‚Üí Keyword \"s·∫£n ph·∫©m c·ªßa Animo\"\n",
        "  - **Tr∆∞·ªùng h·ª£p 2 ‚Äî S·ª≠a ch√≠nh t·∫£ th∆∞∆°ng hi·ªáu (ƒë·ªô tin c·∫≠y cao)**: Khi QUERY c√≥ d·∫•u hi·ªáu sai ch√≠nh t·∫£ th∆∞∆°ng hi·ªáu V√Ä t·∫•t c·∫£ m·ª•c trong CONCUNG_SUGGESTIONS c√πng m·ªôt th∆∞∆°ng hi·ªáu (v√≠ d·ª• ƒë·ªÅu l√† Ensure).\n",
        "    - **M·ª§C ƒê√çCH DUY NH·∫§T**: Chu·∫©n h√≥a t√™n th∆∞∆°ng hi·ªáu trong keyword theo th∆∞∆°ng hi·ªáu chung t·ª´ CONCUNG_SUGGESTIONS.\n",
        "    - **V√≠ d·ª•**:\n",
        "      - QUERY \"en sua\" + CONCUNG_SUGGESTIONS \"s·ªØa Ensure, s·ªØa Ensure Gold, S·ªØa Ensure 237ml\" ‚Üí Keyword \"s·ªØa Ensure dinh d∆∞·ª°ng cho ng∆∞·ªùi l·ªõn\"\n",
        "  - **L∆ØU √ù**: N·∫øu QUERY ‚â• 2 t·ª´ ho·∫∑c ƒë√£ r√µ r√†ng v·ªÅ s·∫£n ph·∫©m ‚Üí B·ªé QUA CONCUNG_SUGGESTIONS, ngo·∫°i tr·ª´ Tr∆∞·ªùng h·ª£p 2 (s·ª≠a ch√≠nh t·∫£ th∆∞∆°ng hi·ªáu ‚Äì ƒë·ªô tin c·∫≠y cao)\n",
        "\n",
        "## 3. X·ª≠ L√Ω ƒê·∫∑c Bi·ªát Cho S·∫£n Ph·∫©m M·∫π v√† B√©\n",
        "- Chuy·ªÉn ƒë·ªïi v·∫•n ƒë·ªÅ s·ª©c kh·ªèe th√†nh nhu c·∫ßu s·∫£n ph·∫©m c·ª• th·ªÉ\n",
        "- X√°c ƒë·ªãnh ƒë·ªô tu·ªïi/c√¢n n·∫∑ng ƒë·ªÉ g·ª£i √Ω size ph√π h·ª£p\n",
        "- T·∫≠p trung v√†o gi·∫£i ph√°p s·∫£n ph·∫©m thay v√¨ m√¥ t·∫£ tri·ªáu ch·ª©ng\n",
        "\n",
        "# QUY T·∫ÆC T·∫†O MESSAGE BANNER (CH·ªà KHI is_in_scope = true)\n",
        "## C·∫•u tr√∫c message banner\n",
        "1. **Th√¥ng ƒëi·ªáp quan t√¢m**: C√¢u n√≥i th·∫•u hi·ªÉu, h·ªó tr·ª£ b·∫±ng ti·∫øng Vi·ªát (t·ªëi ƒëa 100 k√Ω t·ª±)\n",
        "2. **G·ª£i √Ω s·∫£n ph·∫©m**: K·∫øt n·ªëi t√¨m ki·∫øm v·ªõi nhu c·∫ßu/c·∫£m x√∫c c·ªßa kh√°ch h√†ng. Vi·ªác c√≥ nh·∫Øc t√™n th∆∞∆°ng hi·ªáu hay kh√¥ng tu√¢n theo c√°c quy t·∫Øc ∆∞u ti√™n d∆∞·ªõi ƒë√¢y.\n",
        "\n",
        "   - **QUY T·∫ÆC ∆ØU TI√äN (KI·ªÇM TRA ƒê·∫¶U TI√äN)**:\n",
        "       - **M·ª•c ƒë√≠ch**: X√°c nh·∫≠n ch√≠nh x√°c th∆∞∆°ng hi·ªáu khi h·ªá th·ªëng c√≥ ƒë·ªô tin c·∫≠y cao.\n",
        "       - **ƒêI·ªÄU KI·ªÜN**: Ph·∫£i th·ªèa m√£n **C·∫¢ HAI** ƒëi·ªÅu ki·ªán sau: 1) `USER_QUERY` c√≥ ch·ª©a t√™n th∆∞∆°ng hi·ªáu (ho·∫∑c bi·∫øn th·ªÉ sai ch√≠nh t·∫£) V√Ä 2) T·∫•t c·∫£ `CONCUNG_SUGGESTIONS` c√πng tr·ªè v·ªÅ m·ªôt th∆∞∆°ng hi·ªáu duy nh·∫•t ƒë·ªÉ x√°c nh·∫≠n.\n",
        "\n",
        "   - **QUY T·∫ÆC CHUNG (√ÅP D·ª§NG KHI QUY T·∫ÆC ∆ØU TI√äN KH√îNG TH·ªéA M√ÉN)**:\n",
        "       - **M·ª•c ƒë√≠ch**: M√¥ t·∫£ s·∫£n ph·∫©m chung khi kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ th∆∞∆°ng hi·ªáu.\n",
        "\n",
        "   - **S·ª≠ d·ª•ng th·∫ª <b>**: D√πng ƒë·ªÉ nh·∫•n m·∫°nh t·ª´ kh√≥a c√≥ gi√° tr·ªã t√¨m ki·∫øm cao v√† li√™n quan tr·ª±c ti·∫øp ƒë·∫øn 'keyword' ƒë∆∞·ª£c t·∫°o ra.\n",
        "3. **H√†nh ƒë·ªông b·∫Øt bu·ªôc (S√ÅNG T·∫†O BANNER M·ªöI)**:\n",
        "   - **N·∫øu `QUY T·∫ÆC ∆ØU TI√äN` ƒë∆∞·ª£c th·ªèa m√£n**: `message_banner` **B·∫ÆT BU·ªòC** ph·∫£i nh·∫Øc ƒë·∫øn t√™n th∆∞∆°ng hi·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a. D·ª±a v√†o `USER_QUERY`, h√£y **s√°ng t·∫°o m·ªôt th√¥ng ƒëi·ªáp t·ª± nhi√™n v√† th√¢n thi·ªán c√≥ l·ªìng gh√©p t√™n th∆∞∆°ng hi·ªáu** thay v√¨ d√πng m·∫´u c√≥ s·∫µn. T√™n th∆∞∆°ng hi·ªáu ph·∫£i ƒë∆∞·ª£c ƒë·∫∑t trong th·∫ª `<b>`.\n",
        "   - **N·∫øu `QUY T·∫ÆC ∆ØU TI√äN` kh√¥ng ƒë∆∞·ª£c th·ªèa m√£n**: √Åp d·ª•ng `QUY T·∫ÆC CHUNG`. **Ph√¢n t√≠ch s√¢u `USER_QUERY` ƒë·ªÉ n·∫Øm b·∫Øt √Ω ƒë·ªãnh v√† c·∫£m x√∫c c·ªßa kh√°ch h√†ng. T·ª´ ƒë√≥, h√£y t·ª± s√°ng t·∫°o m·ªôt `message_banner` ho√†n to√†n m·ªõi, ph√π h·ª£p v√† ƒë·ªôc ƒë√°o.** Banner c·∫ßn t√≠ch h·ª£p **m√¥ t·∫£ lo·∫°i s·∫£n ph·∫©m ho·∫∑c t√≠nh nƒÉng chung** ƒë∆∞·ª£c r√∫t ra t·ª´ `keyword` m·ªôt c√°ch t·ª± nhi√™n. TUY·ªÜT ƒê·ªêI KH√îNG nh·∫Øc ƒë·∫øn t√™n th∆∞∆°ng hi·ªáu c·ª• th·ªÉ v√† kh√¥ng l·∫∑p l·∫°i c√°c m·∫´u c√¢u nh√†m ch√°n.\n",
        "4. **Emoji**: M·ªôt emoji ph√π h·ª£p (ch·ªß ƒë·ªÅ gia ƒë√¨nh/s·∫£n ph·∫©m t∆∞∆°ng ·ª©ng)\n",
        "5. **Gi·ªçng ƒëi·ªáu**: Quan t√¢m, h·ªó tr·ª£, ƒë√°ng tin c·∫≠y, r·∫•t Vi·ªát Nam\n",
        "6. **C√°ch x∆∞ng h√¥**: S·ª≠ d·ª•ng \"Con C∆∞ng\" ƒë·ªÉ x∆∞ng v√† \"Ba m·∫π\" ƒë·ªÉ g·ªçi kh√°ch h√†ng\n",
        "\n",
        "## H∆∞·ªõng d·∫´n t·∫°o banner\n",
        "- S·ª≠ d·ª•ng ng√¥n ng·ªØ ti·∫øng Vi·ªát nh·∫π nh√†ng, quan t√¢m v·ªõi c√°ch x∆∞ng h√¥ \"Con C∆∞ng\" v√† \"Ba m·∫π\"\n",
        "- Th·ªÉ hi·ªán s·ª± hi·ªÉu bi·∫øt v·ªÅ nhu c·∫ßu kh√°ch h√†ng\n",
        "- X√¢y d·ª±ng ni·ªÅm tin v√† s·ª± t·ª± tin\n",
        "- Tr√°nh ƒë∆∞a ra l·ªùi khuy√™n y t·∫ø ho·∫∑c g√¢y √°p l·ª±c\n",
        "- K·∫øt n·ªëi v·ªõi t√¨nh c·∫£m v√† s·ª± chƒÉm s√≥c\n",
        "- Ph√π h·ª£p v·ªõi vƒÉn h√≥a Vi·ªát Nam\n",
        "- **B·∫ÆT BU·ªòC**: H·∫°n ch·∫ø t·ªëi ƒëa vi·ªác nh·∫Øc t√™n th∆∞∆°ng hi·ªáu c·ª• th·ªÉ, tr·ª´ tr∆∞·ªùng h·ª£p ngo·∫°i l·ªá ƒë√£ n√™u tr√™n.\n",
        "\n",
        "# QUY T·∫ÆC T·∫†O MESSAGE KH√îNG T√åM TH·∫§Y S·∫¢N PH·∫®M (message_no_result)\n",
        "\n",
        "## C·∫•u Tr√∫c B·∫Øt Bu·ªôc (2 Ph·∫ßn)\n",
        "1.  **B√†y T·ªè ƒê·ªìng C·∫£m**: Lu√¥n b·∫Øt ƒë·∫ßu b·∫±ng m·ªôt c√¢u th·ªÉ hi·ªán s·ª± ti·∫øc nu·ªëi nh·∫π nh√†ng. H√£y ƒëa d·∫°ng c√°ch m·ªü ƒë·∫ßu.\n",
        "    - *V√≠ d·ª•*: \"√îi, Con C∆∞ng ch∆∞a t√¨m th·∫•y...\", \"Con C∆∞ng t√¨m k·ªπ m√† ch∆∞a ra...\", \"Hmm, Con C∆∞ng t√¨m ch∆∞a ra r·ªìi...\", \"Ti·∫øc qu√°, Con C∆∞ng ch∆∞a t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m...\"\n",
        "2.  **H∆∞·ªõng D·∫´n Gi·∫£i Ph√°p Th√¥ng Minh**: Ph√¢n t√≠ch `USER_QUERY` ƒë·ªÉ ƒë∆∞a ra **ph∆∞∆°ng ph√°p** c·∫£i thi·ªán t√¨m ki·∫øm, **kh√¥ng g·ª£i √Ω t·ª´ kh√≥a c·ª• th·ªÉ**.\n",
        "    - **Query c√≥ th·ªÉ sai ch√≠nh t·∫£**: G·ª£i √Ω \"Ba m·∫π ki·ªÉm tra l·∫°i t√™n s·∫£n ph·∫©m nh√©!\".\n",
        "    - **Query qu√° d√†i/chi ti·∫øt**: G·ª£i √Ω \"Ba m·∫π th·ª≠ d√πng t·ª´ kh√≥a ng·∫Øn g·ªçn h∆°n xem sao ·∫°!\".\n",
        "    - **Query qu√° ng·∫Øn/chung chung**: G·ª£i √Ω \"Ba m·∫π th·ª≠ b·ªï sung th√™m th√¥ng tin chi ti·∫øt (v√≠ d·ª•: th∆∞∆°ng hi·ªáu, ƒë·ªô tu·ªïi) nh√©!\".\n",
        "    - **C√°c tr∆∞·ªùng h·ª£p kh√°c**: G·ª£i √Ω \"Ba m·∫π th·ª≠ t√¨m v·ªõi m·ªôt t·ª´ kh√≥a kh√°c nh√©!\".\n",
        "\n",
        "## Nguy√™n T·∫Øc V√†ng\n",
        "- **Gi·ªçng ƒëi·ªáu & X∆∞ng H√¥**: Lu√¥n nh·∫π nh√†ng, ƒë·ªìng c·∫£m, h·ªó tr·ª£. X∆∞ng h√¥ \"Con C∆∞ng\" v√† \"Ba m·∫π\".\n",
        "- **ƒê·ªô d√†i**: Ng·∫Øn g·ªçn (15-25 t·ª´, t·ªëi ƒëa 150 k√Ω t·ª±), vƒÉn phong ƒëa d·∫°ng, kh√¥ng l·∫∑p l·∫°i.\n",
        "- **Th√°i ƒë·ªô**: Tr√°nh kh·∫≥ng ƒë·ªãnh \"kh√¥ng c√≥\", thay b·∫±ng \"ch∆∞a t√¨m th·∫•y\". Tuy·ªát ƒë·ªëi kh√¥ng c√≥ h√†m √Ω ng∆∞·ªùi d√πng t√¨m sai.\n",
        "- **T√™n Th∆∞∆°ng Hi·ªáu**: **TUY·ªÜT ƒê·ªêI KH√îNG** nh·∫Øc ƒë·∫øn t√™n th∆∞∆°ng hi·ªáu, tr·ª´ khi l·∫∑p l·∫°i ch√≠nh x√°c `USER_QUERY` ƒë·ªÉ x√°c nh·∫≠n.\n",
        "- **Nh·∫•n m·∫°nh**: Khi l·∫∑p l·∫°i `USER_QUERY`, ƒë·∫∑t trong th·∫ª `<b>`. V√≠ d·ª•: \"Con C∆∞ng t√¨m m√£i ch∆∞a ra <b>t√£ gi·∫•y Huggies</b>.\"\n",
        "- **K·∫øt th√∫c**: Lu√¥n c√≥ m·ªôt emoji th√¢n thi·ªán ·ªü cu·ªëi.\n",
        "\n",
        "# V√ç D·ª§ MINH H·ªåA\n",
        "\n",
        "## C√°c tr∆∞·ªùng h·ª£p is_in_scope = true\n",
        "**ƒê·∫ßu v√†o**: \"b√© 6 th√°ng b·ªã t√°o b√≥n n√™n u·ªëng s·ªØa g√¨\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": true, \"keyword\": \"s·ªØa c√¥ng th·ª©c d·ªÖ ti√™u h√≥a cho b√© 6 th√°ng ch·ªëng t√°o b√≥n\", \"message_banner\": \"Con kh√≥c ƒë√™m nhi·ªÅu ph·∫£i kh√¥ng ba m·∫π? Con C∆∞ng t√¨m ƒë∆∞·ª£c nh·ªØng <b>s·ªØa c√¥ng th·ª©c</b> t·ªët nh·∫•t cho b√©! üçº\", \"message_no_result\": \"Ti·∫øc qu√°, Con C∆∞ng ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m cho b√©. Ba m·∫π th·ª≠ t√¨m b·∫±ng t·ª´ kh√≥a ng·∫Øn g·ªçn h∆°n nh√©! ü§î\"}`\n",
        "\n",
        "**ƒê·∫ßu v√†o**: \"t√£ gi·∫•y huggies\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": true, \"keyword\": \"t√£ gi·∫•y huggies cho b√©\", \"message_banner\": \"Ba m·∫π ƒëang t√¨m <b>t√£ Huggies</b> ph·∫£i kh√¥ng? Con C∆∞ng c√≥ nhi·ªÅu l·ª±a ch·ªçn ti·ªán l·ª£i v√† an to√†n cho b√© y√™u nh√©! üë∂\", \"message_no_result\": \"Con C∆∞ng t√¨m m√£i ch∆∞a ra <b>t√£ gi·∫•y Huggies</b>. Ba m·∫π th·ª≠ ki·ªÉm tra l·∫°i t√™n s·∫£n ph·∫©m ho·∫∑c t√¨m v·ªõi t·ª´ kh√≥a chung h∆°n nh√©! ü•∫\"}`\n",
        "\n",
        "**ƒê·∫ßu v√†o**: \"bao cao su\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": true, \"keyword\": \"bao cao su an to√†n\", \"message_banner\": \"S·∫£n ph·∫©m ch√≠nh h√£ng, <b>ch·∫•t l∆∞·ª£ng ƒë·∫£m b·∫£o</b> - Con C∆∞ng tin ba m·∫π s·∫Ω an t√¢m cho s·ª©c kh·ªèe gia ƒë√¨nh üíï\", \"message_no_result\": \"Hmm, Con C∆∞ng ch∆∞a t√¨m ra <b>bao cao su</b>. Ba m·∫π th·ª≠ b·ªï sung th√™m th√¥ng tin chi ti·∫øt v·ªÅ s·∫£n ph·∫©m nh∆∞ th∆∞∆°ng hi·ªáu mong mu·ªën nh√©! ü§ó\"}`\n",
        "\n",
        "## C√°c tr∆∞·ªùng h·ª£p is_in_scope = false\n",
        "**ƒê·∫ßu v√†o**: \"th·ªùi ti·∫øt h√¥m nay nh∆∞ th·∫ø n√†o\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": false, \"keyword\": \"\", \"message_banner\": \"\", \"message_no_result\": \"R·∫•t ti·∫øc, Con C∆∞ng kh√¥ng c√≥ th√¥ng tin v·ªÅ th·ªùi ti·∫øt. Ba m·∫π th·ª≠ t√¨m ki·∫øm m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ nh√©! ü§î\", \"reasoning\": \"Truy v·∫•n h·ªèi v·ªÅ th·ªùi ti·∫øt, kh√¥ng li√™n quan ƒë·∫øn s·∫£n ph·∫©m.\"}`\n",
        "\n",
        "**ƒê·∫ßu v√†o**: \"Shopee c√≥ t·ªët h∆°n Concung kh√¥ng\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": false, \"keyword\": \"\", \"message_banner\": \"\", \"message_no_result\": \"Con C∆∞ng r·∫•t ti·∫øc kh√¥ng th·ªÉ so s√°nh v·ªõi n·ªÅn t·∫£ng kh√°c. Ba m·∫π c·∫ßn t√¨m s·∫£n ph·∫©m g√¨ ·∫°? ü§ó\", \"reasoning\": \"Truy v·∫•n so s√°nh v·ªõi ƒë·ªëi th·ªß c·∫°nh tranh.\"}`\n",
        "\n",
        "**ƒê·∫ßu v√†o**: \"c√°ch n·∫•u ch√°o cho b√©\"\n",
        "**ƒê·∫ßu ra**: `{\"is_in_scope\": false, \"keyword\": \"\", \"message_banner\": \"\", \"message_no_result\": \"Con C∆∞ng ch∆∞a c√≥ c√¥ng th·ª©c n·∫•u ƒÉn ·∫°. Ba m·∫π c√≥ mu·ªën t√¨m c√°c lo·∫°i ch√°o ƒÉn li·ªÅn dinh d∆∞·ª°ng cho b√© kh√¥ng? üç≤\", \"reasoning\": \"Truy v·∫•n h·ªèi v·ªÅ ki·∫øn th·ª©c chung, kh√¥ng ph·∫£i t√¨m ki·∫øm s·∫£n ph·∫©m.\"}`\n",
        "\n",
        "\n",
        "# Y√äU C·∫¶U ƒê·∫¶U RA\n",
        "Ch·ªâ tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá:\n",
        "```json\n",
        "{\n",
        "  \"is_in_scope\": boolean,\n",
        "  \"keyword\": \"t·ª´ kh√≥a t√¨m ki·∫øm ƒë∆∞·ª£c t·ªëi ∆∞u (ch·ªâ khi is_in_scope = true)\",\n",
        "  \"message_banner\": \"banner th√¢n thi·ªán b·∫±ng ti·∫øng Vi·ªát (lu√¥n t·∫°o khi is_in_scope = true)\",\n",
        "  \"message_no_result\": \"th√¥ng b√°o khi kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m (lu√¥n ƒë∆∞·ª£c t·∫°o)\",\n",
        "  \"reasoning\":\"l√Ω do is_in_scope = false 10 - 20 t·ª´\"\n",
        "}\n",
        "```\n",
        "\n",
        "# C√ÅC B∆Ø·ªöC X·ª¨ L√ù\n",
        "1. **Ki·ªÉm tra ph·∫°m vi**: ƒê√°nh gi√° QUERY theo quy t·∫Øc `is_in_scope`.\n",
        "2. **T·∫°o message_no_result**: Lu√¥n t·∫°o `message_no_result` theo c√°c quy t·∫Øc ·ªü tr√™n, b·∫•t k·ªÉ `is_in_scope` l√† g√¨.\n",
        "3. **N·∫øu is_in_scope = false**: Tr·∫£ v·ªÅ JSON v·ªõi `is_in_scope=false`, `keyword=\"\"`, `message_banner=\"\"`, `message_no_result` ƒë√£ t·∫°o, v√† `reasoning` gi·∫£i th√≠ch ng·∫Øn g·ªçn.\n",
        "4. **N·∫øu is_in_scope = true**:\n",
        "   - **Ph√¢n t√≠ch QUERY**: X√°c ƒë·ªãnh ƒë·ªô chi ti·∫øt v√† r√µ r√†ng c·ªßa query.\n",
        "   - **X·ª≠ l√Ω CONCUNG_SUGGESTIONS** (khi c·∫ßn thi·∫øt):\n",
        "     - Ph√¢n t√≠ch suggestions ƒë·ªÉ t√¨m th∆∞∆°ng hi·ªáu ch√≠nh x√°c v√† th√¥ng tin s·∫£n ph·∫©m.\n",
        "     - ∆Øu ti√™n s·ª≠ d·ª•ng th∆∞∆°ng hi·ªáu t·ª´ suggestions n·∫øu c√≥.\n",
        "     - Gi·ªØ nguy√™n t·ª´ kh√≥a c·ªët l√µi t·ª´ QUERY.\n",
        "     - Ch·ªâ b·ªï sung th√¥ng tin lo·∫°i s·∫£n ph·∫©m chung t·ª´ suggestions, kh√¥ng th√™m c√°c chi ti·∫øt c·ª• th·ªÉ.\n",
        "     - KH√îNG s·ª≠ d·ª•ng suggestions cho `message_banner`.\n",
        "     - Chu·∫©n h√≥a ch√≠nh t·∫£ th∆∞∆°ng hi·ªáu (ƒë·ªô tin c·∫≠y cao): N·∫øu t·∫•t c·∫£ CONCUNG_SUGGESTIONS c√πng m·ªôt th∆∞∆°ng hi·ªáu ‚Üí s·ª≠a th∆∞∆°ng hi·ªáu trong `keyword` theo t√™n ƒë√∫ng; kh√¥ng th√™m thu·ªôc t√≠nh m·ªõi t·ª´ CONCUNG_SUGGESTIONS.\n",
        "   - Tr√≠ch xu·∫•t nhu c·∫ßu s·∫£n ph·∫©m c·ªët l√µi.\n",
        "   - X√°c ƒë·ªãnh thu·ªôc t√≠nh s·∫£n ph·∫©m (ƒë·ªô tu·ªïi, size, th∆∞∆°ng hi·ªáu...).\n",
        "   - Chuy·ªÉn ƒë·ªïi v·∫•n ƒë·ªÅ th√†nh gi·∫£i ph√°p s·∫£n ph·∫©m.\n",
        "   - T·ªëi ∆∞u th√†nh t·ª´ kh√≥a t√¨m ki·∫øm hi·ªáu qu·∫£ (C√ì TH·ªÇ bao g·ªìm t√™n th∆∞∆°ng hi·ªáu t·ª´ query g·ªëc).\n",
        "   - **T·∫°o `message_banner` theo quy tr√¨nh nghi√™m ng·∫∑t sau**:\n",
        "     - **B1: Ki·ªÉm tra \"QUY T·∫ÆC ∆ØU TI√äN\"**. N·∫øu ƒë·ªß ƒëi·ªÅu ki·ªán, t·∫°o banner C√ì ch·ª©a t√™n th∆∞∆°ng hi·ªáu v√† chuy·ªÉn sang b∆∞·ªõc ti·∫øp theo.\n",
        "     - **B2: N·∫øu kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán ∆∞u ti√™n**, t·∫°o banner theo \"QUY T·∫ÆC CHUNG\" (tuy·ªát ƒë·ªëi kh√¥ng ch·ª©a t√™n th∆∞∆°ng hi·ªáu).\n",
        "   - **CRITICAL**: ƒê·∫£m b·∫£o `message_banner` tu√¢n th·ªß ƒë√∫ng quy tr√¨nh B1-B2 ·ªü tr√™n. `message_no_result` ch·ªâ ƒë∆∞·ª£c ph√©p ch·ª©a t√™n th∆∞∆°ng hi·ªáu khi tr√≠ch d·∫´n l·∫°i `USER_QUERY` v√† ƒë·∫∑t trong th·∫ª `<b>`.\n",
        "   - Tr·∫£ v·ªÅ JSON v·ªõi `keyword`, `message_banner`, v√† `message_no_result` ƒë√£ ƒë∆∞·ª£c t·∫°o.\n",
        "-----\n",
        "                # D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO\n",
        "                QUERY: ƒë·ªìng h·ªì chim nh·∫°i gi·ªçng \n",
        "                CONCUNG_SUGGESTIONS: \"xe √¥ t√¥ ƒë·ªìng h·ªì, v√≤ng tay b√© g√°i ƒë·ªìng h·ªì, v·ªõ ƒë·ªìng Natri b√© trai\" \n",
        "\"\"\"\n",
        "\n",
        "answer = ask_question(my_question,  temperature=0.7)\n",
        "print(f\"C√¢u h·ªèi: {my_question}\")\n",
        "print(f\"\\nTr·∫£ l·ªùi:\\n{answer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# X√≥a GPU cache n·∫øu g·∫∑p v·∫•n ƒë·ªÅ v·ªÅ memory\n",
        "clear_gpu_memory()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
        "    print(f\"GPU memory allocated: {allocated:.2f} GB\")\n",
        "    print(f\"GPU memory reserved: {reserved:.2f} GB\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
